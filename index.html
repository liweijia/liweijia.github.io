<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Weijia  Li</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Weijia</span>   Li
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          <!-- blog is removed -->
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/Group/">
                Group
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/liweijia-2.png">
      
      
    </div>
    

    <div class="clearfix">
      <h1 class="post-title">
<b>Weijia Li 李唯嘉</b>
</h1>

<p>Associate Professor</p>

<p>School of Geospatial Engineering and Science</p>

<p>Sun Yat-Sen University</p>

<p>Email: liweij29@mail.sysu.edu.cn</p>

<p><a href="https://scholar.google.com/citations?hl=en&amp;user=R6Rnh9IAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Google Scholar</a></p>

<p>I am currently an Associate Professor at Sun Yat-Sen University. Previously, I was a Post-doc Researcher (2019-2021) at CUHK-Sensetime Joint Lab (<a href="http://mmlab.ie.cuhk.edu.hk/index_cn.html">MMLab</a>), Department of Information Engineering, CUHK, working with <a href="http://dahua.site/">Prof. Dahua Lin</a>. I received my Ph.D. (2014-2019) from Department of Earth System Science, Tsinghua Univeristy, advised by <a href="https://www.thuhpgc.net/mediawiki/index.php/Haohuan_Fu">Prof. Haohuan Fu</a>, and the Bachelor degree (2010-2014) from Department of Computer Science, Sun Yat-Sen Univeristy.</p>

<p>My research interests include computer vision, deep learning, and their applications in urban remote sensing, with a recent focus on large multimodal models and generative models. I serve as a reviewer for many SCI journals and TOP conferences, including RSE, ISPRS P&amp;RS, IEEE TIP/TGRS/TCSVT, CVPR, ICCV, ECCV, NeurIPS, ICLR, AAAI, etc.</p>

<p>I am looking for self-motivated graduate/undergraduate students and research interns. We have close research collaboration with <a href="https://www.shlab.org.cn/">Shanghai Artificial Intelligence Lab</a>. Please feel free to contact me if you are interested!</p>

<p>课题组常年招收优秀的本科生及科研实习生加入，线上/线下均可，组内已培养多名本科生/研究生在CCF-A类顶会及中科院一区SCI发表一作论文。
课题组与上海人工智能实验室有紧密的研究合作，组内已有多名本科生/研究生在上海AI Lab实习或联合培养，研究方向包括多模态大模型、图像生成等。</p>

<p>课题组招收2026年入学的硕士生，有兴趣的同学请尽早与我邮件联系！</p>

    </div>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Sep 19, 2025</th>
          <td>
            
              Four papers are accepted by <a href="https://neurips.cc/">NeurIPS 2025</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 26, 2025</th>
          <td>
            
              Three papers are accepted by <a href="https://iccv.thecvf.com/">ICCV 2025</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 23, 2025</th>
          <td>
            
              <a href="https://opendatalab.github.io/LOKI/">LOKI</a> is accepted by <a href="https://iclr.cc/Conferences/2025">ICLR 2025</a> as spotlight (scores:8/8/8/8)!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Dec 10, 2024</th>
          <td>
            
              <a href="https://opendatalab.github.io/UrBench/">UrBench</a> and <a href="https://fitzpchao.github.io/vhm_page/">VHM</a> are accepted by <a href="https://aaai.org/Conferences/AAAI-25/">AAAI 2025</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jul 1, 2024</th>
          <td>
            
              Two papers are accepted by <a href="https://eccv2024.ecva.net/">ECCV 2024</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 5, 2024</th>
          <td>
            
              <a href="https://arxiv.org/abs/2404.02638">SG-BEV</a> is selected as Highlight (2.8%) by <a href="https://cvpr.thecvf.com/">CVPR 2024</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Mar 16, 2024</th>
          <td>
            
              <a href="https://ieeexplore.ieee.org/document/10478083">RoadCorrector</a> is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36">IEEE TGRS</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Mar 9, 2024</th>
          <td>
            
              <a href="https://ieeexplore.ieee.org/document/10473130">WS-MTBR-Net</a> is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36">IEEE TGRS</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 27, 2024</th>
          <td>
            
              Three papers are accepted by <a href="https://cvpr.thecvf.com/">CVPR 2024</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 16, 2024</th>
          <td>
            
              One paper is accepted by <a href="https://www.journals.elsevier.com/isprs-journal-of-photogrammetry-and-remote-sensing">ISPRS P&amp;RS</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">May 8, 2023</th>
          <td>
            
              <a href="https://www.sciencedirect.com/science/article/pii/S0924271623001272#b32">PolyCity</a> is accepted by <a href="https://www.journals.elsevier.com/isprs-journal-of-photogrammetry-and-remote-sensing">ISPRS P&amp;RS</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 28, 2023</th>
          <td>
            
              <a href="https://city-super.github.io/omnicity/">OmniCity</a> is accepted by <a href="https://cvpr2023.thecvf.com/">CVPR 2023</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Dec 14, 2022</th>
          <td>
            
              One paper is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36">IEEE TGRS</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Nov 19, 2022</th>
          <td>
            
              One paper is accepted by <a href="https://aaai.org/Conferences/AAAI-23/">AAAI 2023</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Sep 8, 2022</th>
          <td>
            
              Got funded by the NSFC (2023.01.01 - 2025.12.31).

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Mar 21, 2022</th>
          <td>
            
              One paper is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE TPAMI</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Nov 30, 2021</th>
          <td>
            
              I join <a href="http://sges.sysu.edu.cn/">School of Geospatial Engineering and Science, Sun Yat-Sen University</a>.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jul 23, 2021</th>
          <td>
            
              Two papers are accepted by <a href="https://iccv2021.thecvf.com/home">ICCV-2021</a>!

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jul 5, 2021</th>
          <td>
            
              We organize a special issue <a href="https://www.mdpi.com/journal/remotesensing/special_issues/RS_deeplearning">‘Deep Learning in Remote Sensing Application’</a> on Remote Sensing.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 6, 2021</th>
          <td>
            
              One paper is accepted by <a href="https://www.journals.elsevier.com/isprs-journal-of-photogrammetry-and-remote-sensing">ISPRS Journal of Photogrammetry and Remote Sensing</a>!

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/Spot-the-Fake-arXiv-2025-1.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="wen2025spot" class="col-sm-8">
    
      <div class="title">Spot the Fake: Large Multimodal Model-Based Synthetic Image Detection with Artifact Explanation</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  Siwei Wen#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Junyan Ye#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Peilin Feng,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Hengrui Kang,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Zichen Wen,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Yize Chen,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jiang Wu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Wenjun Wu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Conghui He,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and <b>Weijia</b> <b>Li*</b>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>NeurIPS</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://doi.org/10.48550/arXiv.2503.14905" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    	 
    
    
    
    
      <a href="https://github.com/opendatalab/FakeVLM" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">ICCV</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/LEGION-arXiv-2025-2.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="kang2025legion" class="col-sm-8">
    
      <div class="title">LEGION: Learning to Ground and Explain for Synthetic Image Detection</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  Hengrui Kang#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Siwei Wen#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Zichen Wen#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Junyan Ye,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  <b>Weijia</b> <b>Li*</b>,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Peilin Feng,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Baichuan Zhou,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Bin Wang,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Dahua Lin,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Linfeng Zhang,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Conghui He*
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ICCV (Highlight)</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://doi.org/10.48550/arXiv.2503.15264" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    
      
      <a href="https://opendatalab.github.io/LEGION" class="btn btn-sm z-depth-0" role="button" target="_blank">project</a>
      
    	 
    
    
    
    
      <a href="https://github.com/opendatalab/LEGION" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">ICCV</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/Where_am_i-arXiv-2024-1.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="ye2024cross" class="col-sm-8">
    
      <div class="title">Where am I? Cross-View Geo-localization with Natural Language Descriptions</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  Junyan Ye#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Honglin Lin#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Leyan Ou,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Dairong Chen,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Zihao Wang,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Conghui He,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and <b>Weijia</b> <b>Li*</b>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ICCV</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://doi.org/10.48550/arXiv.2412.17007" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    
      
      <a href="https://yejy53.github.io/CVG-Text/" class="btn btn-sm z-depth-0" role="button" target="_blank">project</a>
      
    	 
    
    
    
    
      <a href="https://github.com/yejy53/CVG-Text" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">ICCV</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/skydiffusion-arXiv-2024-1.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="ye2024skydiffusion" class="col-sm-8">
    
      <div class="title">Leveraging BEV Paradigm for Ground-to-Aerial Image Synthesis</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  Junyan Ye,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jun He,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  <b>Weijia</b> <b>Li*</b>,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Zhutao Lv,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jinhua Yu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Haote Yang,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Conghui He
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ICCV</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://arxiv.org/abs/2408.01812" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    
      
      <a href="https://opendatalab.github.io/skydiffusion" class="btn btn-sm z-depth-0" role="button" target="_blank">project</a>
      
    	 
    
    
    
    
      <a href="https://github.com/opendatalab/skydiffusion" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/LOKI-ICLR-2024-1.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="ye2025loki" class="col-sm-8">
    
      <div class="title">LOKI: A comprehensive synthetic data detection benchmark using large multimodal models</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  Junyan Ye#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Baichuan Zhou#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Zilong Huang#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Junan Zhang#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Tianyi Bai,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Hengrui Kang,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jun He,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Honglin Lin,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Zihao Wang,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Tong Wu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Zhizhen Wu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Yiping Chen,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Dahua Lin,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Conghui He*,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and <b>Weijia</b> <b>Li*</b>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ICLR (Spotlight)</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://doi.org/10.48550/arXiv.2410.09732" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    
      
      <a href="https://opendatalab.github.io/LOKI/" class="btn btn-sm z-depth-0" role="button" target="_blank">project</a>
      
    	 
    
    
    
    
      <a href="https://github.com/opendatalab/LOKI" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">AAAI</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/UrBench-arXiv-2024-1.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="zhou2025urbench" class="col-sm-8">
    
      <div class="title">UrBench: A comprehensive benchmark for evaluating large multimodal models in multi-view urban scenarios</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  Baichuan Zhou#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Haote Yang#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Dairong Chen#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Junyan Ye#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Tianyi Bai,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jinhua Yu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Songyang Zhang,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Dahua Lin,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Conghui He*,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and <b>Weijia</b> <b>Li*</b>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>AAAI</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://doi.org/10.48550/arXiv.2408.17267" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    
      
      <a href="https://opendatalab.github.io/UrBench/" class="btn btn-sm z-depth-0" role="button" target="_blank">project</a>
      
    	 
    
    
    
    
      <a href="https://github.com/opendatalab/UrBench/" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">CVPR</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/SG-BEV-2024-3.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="ye2024sgbev" class="col-sm-8">
    
      <div class="title">SG-BEV: Satellite-Guided BEV Fusion for Cross-View Semantic Segmentation</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  Junyan Ye,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Qiyan Luo,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jinhua Yu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Huaping Zhong,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Zhimeng Zheng,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Conghui He,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and <b>Weijia</b> <b>Li*</b>
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>CVPR (Highlight)</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://arxiv.org/abs/2404.02638" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    	 
    
    
    
    
      <a href="https://github.com/yejy53/SG-BEV" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">CVPR</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/3D-Building-CVPR2024-1.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="li20243d" class="col-sm-8">
    
      <div class="title">3D Building Reconstruction from Monocular Remote Sensing Images with Multi-level Supervisions</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  <b>Weijia</b> <b>Li#</b>,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Haote Yang#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Zhenghao Hu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Juepeng Zheng,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Gui-Song Xia,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Conghui He*
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>CVPR</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://arxiv.org/abs/2404.04823" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    	 
    
    
    
    
      <a href="https://github.com/opendatalab/MLS-BRN" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">ECCV</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/Cross-view-ECCV-2024-2.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="ye2024eccv" class="col-sm-8">
    
      <div class="title">Cross-view image geo-localization with Panorama-BEV Co-Retrieval Network</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  Junyan Ye,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Zhutao Lv,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  <b>Weijia</b> <b>Li*</b>,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jinhua Yu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Haote Yang,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Huaping Zhong,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Conghui He*
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ECCV</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://arxiv.org/abs/2408.05475" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    	 
    
    
    
    
      <a href="https://github.com/yejy53/EP-BEV" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">TGRS</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/RoadCorrector-TGRS-2024-1.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="li2024road" class="col-sm-8">
    
      <div class="title">RoadCorrector: A Structure-aware Road Extraction Method for Road Connectivity and Topology Correction</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  Jinpeng Li#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jun He#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  <b>Weijia</b> <b>Li*</b>,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jiabin Chen,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Jinhua Yu
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Geoscience and Remote Sensing</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://ieeexplore.ieee.org/abstract/document/10478083" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    	 
    
    
    
    
      <a href="https://github.com/Lijp411/RoadCorrector" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">CVPR</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/Omnicity-CVPR-2023-1.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="li2023omnicity" class="col-sm-8">
    
      <div class="title">OmniCity: Omnipotent City Understanding with Multi-level and Multi-view Images</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  <b>Weijia</b> <b>Li</b>,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Yawen Lai,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Linning Xu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Yuanbo Xiangli,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jinhua Yu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Conghui He*,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Gui-Song Xia*,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Dahua Lin
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>CVPR</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Li_OmniCity_Omnipotent_City_Understanding_With_Multi-Level_and_Multi-View_Images_CVPR_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    
      
      <a href="https://city-super.github.io/omnicity/" class="btn btn-sm z-depth-0" role="button" target="_blank">project</a>
      
    	 
    
      
      <a href="https://www.youtube.com/watch?v=-lrFgcyyCHQ" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
      
    
    
    
    
      <a href="https://github.com/sysu-lwj-lab/OmniCity-v1.0" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">ISPRS</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/Joint-ISPRS-2023-3.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="li2023joint" class="col-sm-8">
    
      <div class="title">Joint Semantic-Geometric Learning for Polygonal Building Segmentation from High-Resolution Remote Sensing Images</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  <b>Weijia</b> <b>Li</b>,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Wenqian Zhao,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jinhua Yu,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Juepeng Zheng*,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Conghui He,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Haohuan Fu*,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Dahua Lin
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ISPRS Journal of Photogrammetry and Remote Sensing</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="https://www.sciencedirect.com/science/article/pii/S0924271623001272#b32" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    	 
    
    
    
    
      <a href="https://github.com/liweijia/polycity" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">ICCV</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/3D-Building-iccv-2021-1.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="ICCV-3D" class="col-sm-8">
    
      <div class="title">3D Building Reconstruction from Monocular Remote Sensing Images</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  <b>Weijia</b> <b>Li#</b>,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Lingxuan Meng#,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Jinwang Wang,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Conghui He,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Gui-Song Xia,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Dahua Lin
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ICCV</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="/assets/pdf/ICCV-21-paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    	 
    
      
      <a href="https://www.youtube.com/watch?v=q055pYWv3FM&t=63s" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
      
    
    
    
    
    
    
      
      <a href="/assets/pdf/ICCV-21-slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3 abbr">
  
    
    <abbr class="badge">AAAI</abbr>
    
  
  <img 
    class="teaser" 
    src="/assets/img/paper_img/Joint-AAAI2021-1.png"
    style="max-width: 100%; height: 100%; object-fit: contain;"
    >
  </div>


  <div id="AAAI-joint" class="col-sm-8">
    
      <div class="title">Joint Semantic-Geometric Learning for Polygonal Building Segmentation</div>
      <div class="author">
        
          
          
          
          

          
            
              
                
                  <b>Weijia</b> <b>Li</b>,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Wenqian Zhao,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Huaping Zhong,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  Conghui He*,
                
              
            
          
        
          
          
          
          

          
            
              
                
                  and Dahua Lin
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>AAAI</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
    
    
    
    
      
      <a href="/assets/pdf/AAAI-21-paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Paper</a>
      
    
    	 
    
    
    
    
    
    
      
      <a href="/assets/pdf/AAAI-21-slides-20min.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
  </div>
</div>
</li></ol>
</div>

    

    
    <div class="social">
      <span class="contact-icon text-center">
  <a href="mailto:%6C%69%77%65%69%6A%69%61%36%32%31@%67%6D%61%69%6C.%63%6F%6D"><i class="fas fa-envelope"></i></a>
  
  <a href="https://scholar.google.com/citations?user=R6Rnh9IAAAAJ&hl=en" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
  
  <a href="https://www.researchgate.net/profile/Weijia_Li3/" target="_blank" title="ResearchGate"><i class="ai ai-researchgate"></i></a>
  <a href="https://github.com/liweijia" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
  
  
  
  
  
  
  
  
  
</span>

      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2026 Weijia  Li.
    
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
